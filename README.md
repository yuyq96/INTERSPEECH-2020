# INTERSPEECH2020

## Mon-1-1 ASR Neural Network Architectures I

- [x] Zhifu Gao, ShiLiang Zhang, Ming Lei, Ian McLoughlin. *SAN-M: Memory Equipped Self-Attention for End-to-End Speech Recognition.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-1-1-2.pdf)]
  - `ASR` `AISHELL-1`
  - Value + DFSMN

## Mon-1-4 Speech Signal Representation

## Mon-1-5 Speech Synthesis: Neural Waveform Generation I

## Mon-1-7 Speaker Diarization

## Mon-1-8 Noise Robust and Distant Speech Recognition

## Mon-1-11 Language Recognition

## Mon-2-1 Speech Emotion Recognition I (SER I)

## Mon-2-2 ASR Neural Network Architectures and Training I

## Mon-2-3 Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation

## Mon-2-4 Phonetics and Phonology

## Mon-2-5 Topics in ASR I

## Mon-2-6 Large-Scale Evaluation of Short-Duration Speaker Verification

## Mon-2-7 Voice Conversion and Adaptation I

## Mon-2-8 Acoustic Event Detection

## Mon-2-9 Spoken Language Understanding I

## Mon-2-10 DNN Architectures for Speaker Recognition

- [x] Ya-Qi Yu, Wu-Jun Li. *Densely Connected Time Delay Neural Network for Speaker Verification.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-2-10-2.pdf)]
  - `SI-SV` `VoxCeleb` `Dense Connection` `Multi-brach`
  - Densely Connected TDNN (D-TDNN)
  - Statistics-and-Selection (attention-based weights)
    - Q: Fixed
    - K: Global embedding vector (equal weights)
    - V: Hidden feature vector

- [x] Siqi Zheng, Hongbin Suo, Yun Lei. *Phonetically-Aware Coupled Network For Short Duration Text-independent Speaker Verification.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-2-10-3.pdf)]
  - `SI-SV` `Short Duration` `NIST SRE` `VoxCeleb` `Phonetic Information` `Triplet Loss`
  - Phonetically-Aware Coupled Network (PacNet)
  - 'Triplet loss training scheme is more fitting than softmax loss system for normalizing phonetic contents.'

- [x] Myunghun Jung, Youngmoon Jung, Jahyun Goo, Hoi Rin Kim. *Multi-Task Network for Noise-Robust Keyword Spotting and Speaker Verification using CTC-based Soft VAD and Global Query Attention.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-2-10-4.pdf)]
  - `SI-SV` `KWS` `Phonetic Information`
  - Global Query Attention (attention-based weights)
    - Q: Global embedding vector (LSTM-based weights)
    - KV: Hidden feature vector

## Mon-2-11 ASR Model Training and Strategies

## Mon-3-1 Cross/Multi-Lingual and Code-Switched Speech Recognition

## Mon-3-2 Anti-Spoofing and Liveness Detection

## Mon-3-3 Noise Reduction and Intelligibility

## Mon-3-4 Acoustic Scene Classification

## Mon-3-5 Singing Voice Computing and Processing in Music

## Mon-3-7 Acoustic Model Adaptation for ASR

## Mon-3-8 Singing and Multimodal Synthesis

## Mon-3-9 Intelligibility-Enhancing Speech Modification

## Mon-3-10 Human Speech Production I

## Mon-3-11 Targeted Source Separation  

- [ ] Meng Ge, Chenglin Xu, Longbiao Wang, Eng Siong Chng, Jianwu Dang, Haizhou Li. *SpEx+: A Complete Time Domain Speaker Extraction Network.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-3-11-1.pdf)]

- [x] Tingle Li, Qingjian Lin, Yuanyuan Bao, Ming Li. *Atss-Net: Target Speaker Separation via Attention-based Neural Network.* [[INTERSPEECH 2020](http://www.interspeech2020.org/uploadfile/pdf/Mon-3-11-2.pdf)]
